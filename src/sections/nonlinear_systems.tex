\section{Nonlinear Systems}

\subsection{Concepts of Stability}
A nonlinear system
\noindent\begin{align*}
    \dot{\mathbf{x}}(t) & = f(\mathbf{x}(t), \mathbf{u}(t)) & \mathbf{x}(0)=\mathbf{x}_0 \\
    \mathbf{y}(t)       & = h(\mathbf{x}(t), \mathbf{u}(t))
\end{align*}
\textbf{does not satisfy the superposition property} and therefore
\begin{itemize}
    \item Effects from inputs and from initial conditions cannot be separated.
    \item The input cannot be separated into elementary inputs and the output will not be a composition of elementary outputs.
\end{itemize}

\newpar{}
\ptitle{Properties}
\begin{itemize}
    \item A nonlinear system can have zero, one or multiple \textbf{equilibrium points} s.t.\ $f(\mathbf{x}_e, 0)=0$.
    \item In contrast to linear systems that require infinite time to go to infinity, nonlinear systems can \textbf{go to infinity in finite time}.
    \item Nonlinear systems may generate permanent oscillations of fixed amplitude - \textbf{limit cycles} - independent of initial conditions.
    \item Nonlinear systems can generate outputs at frequencies that are submultiples or multiples of the input frequency (\textbf{Subharmonic oscillations}).
    \item Deterministic nonlinear systems can generate \textbf{chaos}.
\end{itemize}

\subsection{Lyapunov Stability Theory}
Lyapunov's theorem only gives a sufficient condition for stability
\begin{itemize}
    \item If we can find a Lyapunov function, then we know the equilibrium is stable.
    \item However, if a candidate Lyapunov function does not satisfy the conditions in the theorem, this does not prove that the equilibrium is unstable.
\end{itemize}
General Lyapunov functions are
\begin{itemize}
    \item Energy
    \item Quadratic Lyapunov functions are commonly used; these can be derived from linearization of the system near equilibrium points.
    \item “Sum-of-Squares” (SoS) methods can be used to construct polynomial Lyapunov functions
\end{itemize}

\subsubsection{Types of Stability}
Assuming $\mathbf{u}=0, \mathbf{x}_e=0$, then in the equilibrium $\mathbf{x}_e$ of the system
\begin{equation*}
    \dot{\mathbf{x}} = f(\mathbf{x})
\end{equation*}
one has
\noindent\begin{equation*}
    f(\mathbf{x}_e) = 0
\end{equation*}
The equilibrium is said to be
\begin{itemize}
    \item \textbf{Stable in the sense of Lyapunov}
          \noindent\begin{equation*}
              \|\mathbf{x}(0)\| < \delta \Rightarrow \|\mathbf{x}(t)\| \leq \varepsilon,\qquad \forall t\geq 0,\; \delta > 0,\; \varepsilon\geq0
          \end{equation*}
    \item \textbf{Asymptotically stable}
          \noindent\begin{equation*}
              \|\mathbf{x}(0)\| < \delta \Rightarrow \lim_{t\to +\infty} \mathbf{x}(t)=0, \qquad \delta>0
          \end{equation*}
    \item \textbf{Exponentially stable}
          \noindent\begin{equation*}
              \|\mathbf{x}(0)\| < \delta \Rightarrow \|\mathbf{x}(t)\| < \beta e^{-\alpha t}, \qquad \forall t\geq 0,\; \alpha, \beta, \delta >0
          \end{equation*}
\end{itemize}

\subsubsection{Lyapunov Functions}
\textit{Lyapunov functions are, in a sense, a notion of energy: non-negative, minimized (0) only at the equilibrium point and non-increasing along all trajectories.}

\newpar{}
For a given compact subset $D$ of the state space containing $\mathbf{x}_e$, a Lyapunov function is defined as
\noindent\begin{equation*}
    V:D \to \mathbb{R} \mapsto V(\mathbf{x})
\end{equation*}

If this Lyapunov function satisfies
\noindent\begin{align*}
    V(\mathbf{x})          & \geq 0                                                                                                                                                                   &  & \forall \mathbf{x}\in D    \\
    V(\mathbf{x})          & = 0 \Leftrightarrow \mathbf{x}_e = \mathbf{x}                                                                                                                            &  & \text{(if and only if)}    \\
    \dot{V}(\mathbf{x}(t)) & = \frac{\partial V(\mathbf{x})}{\partial \mathbf{x}} \frac{\partial \mathbf{x}(t)}{\partial t} = \frac{\partial V(\mathbf{x})}{\partial \mathbf{x}} f(\mathbf{x}) \leq 0 &  & \forall \mathbf{x}(t)\in D
\end{align*}
the equilibrium point $\mathbf{x_e}$ is \textbf{stable in the sense of Lyapunov}. Remember that $V$ is defined on a set containing $\mathbf{x}_e$.

\newpar{}
Futhermore, $\mathbf{x}_e$ is \textbf{asymptotically stable} if
\noindent\begin{equation*}
    \dot{V}(\mathbf{x}(t)) = 0 \Leftarrow \mathbf{x}(t) = \mathbf{x}_e \quad \text{(only if)}
\end{equation*}
Finally, $\mathbf{x}_e$ is \textbf{exponentially stable} if
\noindent\begin{equation*}
    \dot{V}(\mathbf{x}(t)) < -\alpha V(\mathbf{x}(t)), \qquad \alpha>0
\end{equation*}

\newpar{}
\ptitle{Global Stability}

According to the Barbashin-Krasovski theorem, to ensure global stability (not necessarily asymptotical or exponential), i.e. $D=\mathbb{R}^n$, a Lyapunov function $V$ satisfying the aforementioned three properties \textbf{additionally} needs to be \textbf{radially unbounded}:
\noindent\begin{equation*}
    \|\mathbf{x}\| \to +\infty \Rightarrow V(\mathbf{x}) \to +\infty
\end{equation*}

\newpar{}
\ptitle{Remarks}
\begin{itemize}
    \item If there could be multiple equilibrium points one needs to use LaSalle.
    \item $V(\mathbf{x})=0$ must hold in any equilibrium point, even if there are more then one.
          %TODO:: must the "only equilibrium point" from above be (0,...0)? -> I think not
    \item If one has more than one state vector, then
          \begin{equation*}
              \dot{V}=\sum_{i} \frac{\partial V(\mathbf{x}_i)}{\partial \mathbf{x}_i} \frac{\partial \mathbf{x}_i(t)}{\partial t}
          \end{equation*}
    \item For asymptotical stability, given $\dot{V}(\mathbf{x}(t)) = 0$ we know that the system is in the \textbf{only} equilibrium point.
\end{itemize}

\paragraph{Indirect Method}
For a linear system
\begin{equation*}
    \dot{\mathbf{x}} = \mathbf{Ax}
\end{equation*}
A common choice is a \textit{quadratic Lyapunov function}
\begin{align*}
    V(x) = \mathbf{x}^{T}\mathbf{Px}
\end{align*}
where $\mathbf{P}$ is symmetric and positive definite matrix.

The Derivation along trajectories is given by
\begin{equation*}
    \dot{V}(\mathbf{x}) = \mathbf{x}^{T}\left(\mathbf{A}^{T}\mathbf{P+PA}\right)\mathbf{x} = - \mathbf{x}^{T}\mathbf{Qx}
\end{equation*}
An appropriate matrix $P$ defining the desired Lyapunov function can be found by solving
\begin{equation*}
    \mathbf{A}^{T}\mathbf{P+PA=-Q}
\end{equation*}
This is called the \textbf{Lyapunov Equation}.

\newpar{}
\ptitle{Remark}

The solution $\mathbf{P}$ of the LQR Riccati equation fulfills the criteria of a Lyapunov function $V(x) = \mathbf{x}^{T}\mathbf{Px}$.

\newpar{}
\ptitle{Hartman-Grobman Theorem}

According to the \textbf{Hartman-Grobman Theorem}, a linearized system
\noindent\begin{equation*}
    A = \left.\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}} \right|_{\mathbf{x} = 0}
\end{equation*} with no unstable pole behaves qualitatively the same as the nonlinear around the equilibrium point.

\newpar{}
As a result, the Lyapunov function of the linear system also describes the nonlinear system for sufficiently small deviations from the equilibrium point.

\subsubsection{LaSalle's Invariance Principle}
LaSalle's invariance theorem is useful if Lyapunov stability is given by the existence of a Lyapunov function but $\dot{V}=0$ not only at $\mathbf{x}_e$:

\newpar{}
% taken from https://www.cds.caltech.edu/archive/help/uploads/wiki/files/237/Lecture2_notes_CDS270.pdf
\begin{itemize}[leftmargin=14pt]
    \item Let $\Omega\subset D$ be a compact positively invariant set w.r.t.\ $\dot{\mathbf{x}}$ ($\mathbf{x}$ stays in the set) i.e., $\mathbf{x}(t_0)\in \Omega \Rightarrow \mathbf{x}(t)\in\Omega\; \forall t \geq t_0$.
    \item Let $V:D\to \mathbb{R}^n$, such that $\dot{V}(\mathbf{x})\leq 0\; \forall \mathbf{x}\in \Omega$.
    \item Let $E=\left\{\mathbf{x}: \dot{V}(\mathbf{x})=0\right\}\subset \Omega$ (possibly multiple pts.).
    \item[$\rhd$] Then every solution starting in $\Omega$ approaches $M\subset E$ (largest invariant set in $E$) as $t\to \infty$.
    \item[$\rhd$] This proves asymptotic stability.
\end{itemize}
\newpar{}
\begin{equation*}
    M\subset E \subset \Omega \subset D \subset \mathbb{R}^n
\end{equation*}

\newpar{}
\textbf{Procedure}
\begin{enumerate}
    \item Find the largest invariant set $E=\left\{\mathbf{x}: \dot{V}(\mathbf{x})=0\right\}$
    \item Plug the found set $E$ into the dynamics of the system and check if the system can ``escape'' this set.
\end{enumerate}

\newpar{}
\textbf{Remarks}
\begin{itemize}
    \item For the pendulum with Lyapunov function $\dot{V}(x)=-c\dot{\theta}^2$, one has multiple states (turning points) where $\dot{V}=0$ namely whenever $\dot{\theta}=0$. However the only invariant $\dot{\theta}=0$ is the one in the origin (when the pendulum stopped).
\end{itemize}



\subsection{Control Lyapunov Functions}
If a Control Lyapunov Function (CLF) exists, it provides a way to construct a stabilizing feedback with an appropriate control input $\tilde{\mathbf{u}}$ (\textit{Artstein's Theorem}).

\newpar{}
A CLF satisfies
\noindent\begin{align*}
    V(\mathbf{x})                                              & \geq 0                                                                                           &  & \text{positive definite}  \\
    V(\mathbf{x})                                              & = 0 \Leftrightarrow \mathbf{x} = 0                                                               &  & \text{radially unbounded} \\
    \frac{d}{dt} V(\mathbf{x}, \tilde{\mathbf{u}}(\mathbf{x})) & = \frac{\partial V(\mathbf{x})}{\partial t} f(\mathbf{x}, \tilde{\mathbf{u}}(\mathbf{x})) \leq 0 &  & \forall \mathbf{x}\neq 0
\end{align*}

i.e.\ using the control input $u$, $V$ becomes a Lyapunov function. In the following methods, one aims to find a control Lyapunov function to prove stabilizing behavior with a specific control input.

\subsubsection{Gain Scheduling}
In gain scheduling, the state space is partitioned into disjoint subspaces and for a number of design equilibria ($\mathbf{x}_i, \mathbf{u}_i$)  nominal control laws $\mathbf{K}_i$ are designed using the aforementioned techniques.

\newpar{}
The dynamics of the system around a equilibrium point $\mathbf{x}_i$ can be approximated by
\noindent\begin{equation*}
    \dot{\mathbf{x}} = \mathbf{A}_i(\mathbf{x}-\mathbf{x}_i) + \mathbf{B}_i(\mathbf{u}-\mathbf{u}_i)
\end{equation*}

\paragraph{Common Lyapunov Function}
The stability of
\noindent\begin{equation*}
    \mathbf{u} = \mathbf{u}_i+\mathbf{K}_i(\mathbf{x}-\mathbf{x}_i)
\end{equation*}
in \textbf{all} regions $i$ can be proven by finding a common Lyapunov function
\noindent\begin{equation*}
    V(\mathbf{x}) = \min_{i} {(\mathbf{x}-\mathbf{x}_i)}^{\mathsf{T}}\mathbf{P}(\mathbf{x}-\mathbf{x}_i)
\end{equation*}
\begin{itemize}
    \item Note however, that this is \textbf{not} always possible.
    \item This means that, even if one designs a specific controller for each region, the CL could still be unstable.

\end{itemize}

\subsubsection{Multiple Lyapunov Functions}
Another option is to consider multiple Lyapunov-like functions $V_i$ with corresponding sets $X_i$ that satisfy
\begin{itemize}
    \item positive definite in $X_i$
    \item $\dot{V_i}(\mathbf{x})\leq 0$ when $\mathbf{x}\in X_i$
\end{itemize}
Then, define $V_i[k]$ as infimum taken by $V_i$ in the given time interval and check if the system satisfies the \textbf{sequence non-increasing condition}:
\noindent\begin{equation*}
    V_i[k+1] < V_i[k] \qquad \forall k \in \mathbb{N}
\end{equation*}

\newpar{}
\ptitle{Rationale}

Assuming the system can move from region to region, we look at all time intervals where the system is in a certain region $X_i$. We want to have the Lyapunov function decreased every time the system reenters a certain region again. Defining $V_i$ as infimum (largest lower bound), we have stable behavior if the infimum decreases at every re-entry of region $X_i$.

\subsubsection{Linear Parameter-Varying (LPV) Systems}
A third option is to rewrite the nonlinear system in a ``linear'' fashion with slow varying parameter $\sigma(\mathbf{x})$
\noindent\begin{equation*}
    \dot{\mathbf{x}}_\delta = \mathbf{A} (\sigma(\mathbf{x}))\mathbf{x}_\delta + \mathbf{B}(\sigma(\mathbf{x}))\mathbf{u}_\delta\quad
    \begin{cases}
        \mathbf{x}_\delta = \mathbf{x}-\mathbf{x}_e(\sigma(\mathbf{x})) \\
        \mathbf{u}_\delta = \mathbf{u}-\mathbf{u}_e(\sigma(\mathbf{x}))
    \end{cases}
\end{equation*}

\newpar{}
\ptitle{Lyapunov Condition for LPV}

This system is \textbf{exponentially stable} if
\noindent\begin{equation*}
    {\bar{\mathbf{A}}(\sigma)}^{\mathsf{T}} \mathbf{P} + \mathbf{P}\bar{\mathbf{A}}(\sigma) + \sum \rho_i \frac{\partial \mathbf{P}(\sigma)}{\partial \sigma_i} < 0,\qquad
    \begin{cases}
        \sigma(t)\in S       \\
        \dot{\sigma}(t)\in R \\
        \forall \sigma\in S, \rho\in R
    \end{cases}
\end{equation*}
In other words, the existence of a family of positive matrices $\mathbf{P}(\sigma)$ (common Lyapunov functions) prove the systems exponential stability.

\newpar{}
\ptitle{LPV Controllers}

\begin{itemize}
    \item One assumes $\sigma$ is measurable
    \item Then, one will design a stabilizing controller for every $\sigma$
    \item LPV can be imagined as continuous gain scheduling: one has controllers depending on a (possibly infinite) number of $\sigma$s instead of a number of equilibrium points
\end{itemize}

\subsubsection{Backstepping Control}
Backstepping is a form of \textit{cascaded control} where a control input $\mathbf{u}$ is chosen s.t.\ the output $\mathbf{z}$ of the outer loop stabilizes the inner loop:

\noindent\begin{align*}
    \dot{\mathbf{x}} & = f_0(\mathbf{x}) + g_0(\mathbf{x})\mathbf{z}                         &  & \text{inner loop} \\
    \dot{\mathbf{z}} & = f_1(\mathbf{x},\mathbf{z}) + g_1(\mathbf{x}, \mathbf{z}) \mathbf{u} &  & \text{outer loop}
\end{align*}
where the inner system has an equilibrium point in $\mathbf{x}=0, \mathbf{z}=0$.

\newpar{}
Assuming the inner system is stable for a certain $\mathbf{z} = \mathbf{u}_0(\mathbf{x})$ then
\noindent\begin{equation*}
    \frac{d}{dt} V_0(\mathbf{x}) = -W(\mathbf{x}) < 0
\end{equation*}
Then, in order to ensure stability, Lyapunov stability of the error $\mathbf{e} = \mathbf{z}-\mathbf{u}_0$ needs to be established.
The error evolves as
\begin{align*}
    \dot{\mathbf{x}} & =\mathbf{f}_{0}(\mathbf{x})+\mathbf{g}_{0}(\mathbf{x})\mathbf{u}_{0}(x)+\mathbf{g}_{0}(\mathbf{x})\mathbf{e},                                                                                                                                                                                                                                              \\
    \dot{\mathbf{e}} & =\underbrace{\mathbf{f}_{1}(\mathbf{x},\mathbf{z})+\mathbf{g}_{1}(\mathbf{x},\mathbf{z})\mathbf{u}}_{\dot{\mathbf{z}}}-\underbrace{\frac{\partial \mathbf{u}_{0}(\mathbf{x})}{\partial \mathbf{x}}\overbrace{\left(\mathbf{f}_{0}(\mathbf{x})+\mathbf{g}_{0}(\mathbf{x})\mathbf{z}\right)}^{\dot{\mathbf{x}}}}_{\dot{\mathbf{u}}_0(\mathbf{x})}=\mathbf{v}
\end{align*}
Then, the Lyapunov candidate
\noindent\begin{equation*}
    V_1(\mathbf{x}, \mathbf{e}) = V_0(\mathbf{x})+\frac{1}{2} \mathbf{e}^2
\end{equation*}
satisfies
\noindent\begin{equation*}
    \frac{d}{dt}V_1(\mathbf{x}, \mathbf{e}) = -W(\mathbf{x}) - k_1 \mathbf{e}^2 <0 ,\qquad \forall(\mathbf{x},\mathbf{e}) \neq 0
\end{equation*}
if one cleverly picks
\begin{equation*}
    \mathbf{v}=-\frac{\partial V_0(\mathbf{x})}{\partial \mathbf{x}}\mathbf{g}_0(\mathbf{x})-k_1\mathbf{e},\quad k_1>0
\end{equation*}
and thus proves the stability of the ``error'' system.
% \noindent\begin{align*}
%     \dot{\mathbf{x}} & = f_0(\mathbf{x})+g_0(\mathbf{x})\mathbf{u}_0(\mathbf{x}) + g_0(\mathbf{x})\mathbf{e}                                                               \\
%     \dot{\mathbf{e}} & = \dot{\mathbf{z}} - \underbrace{\frac{\partial \mathbf{u}_0(\mathbf{x})}{\partial \mathbf{x}}(\dot{\mathbf{x}})}_{\dot{\mathbf{u}}_0} = \mathbf{v}
% \end{align*}
Using $\dot{u_0}=\dot{z}-\dot{e}$ one finally finds the stabilizing control law as
\begin{align*}
    u_1(x,z)  = \frac{1}{g_1(x,z)} & \left(\frac{\partial u_0(x)}{\partial x}\left(f_0(x)+g_0(x)z\right)-f_1(x,z) \right. \\
                                   & \left. -\frac{\partial V_0(x)}{\partial x}g_0(x)-k_1(z-u_0(x))\right)
\end{align*}

\newpar{}
\ptitle{Remarks}

\begin{itemize}
    \item The control input $\mathbf{u}$ affects $\mathbf{z}$, which in turn affects $\mathbf{x}$
    \item One assumes that the inner system is easily controllable by $\mathbf{u}_0$ e.g.\ because
          \begin{itemize}
              \item it is linear
              \item one can find a control Lyapunov function for it
          \end{itemize}
    \item The idea can be extended to multiple nested systems
\end{itemize}

\paragraph{Recursive Backstepping}
The same approach can be used recursively as
\begin{align*}
    \dot{x}     & =\quad f_{0}(x)+g_{0}(x)z_{1},                     \\
    \dot{z}_{1} & =\quad f_{1}(x,z_{1})+g_{1}(x,z_{1})z_{2},         \\
                & \vdots                                             \\
    \dot{z}_{m} & =\quad f_{m}(x,z_{1},\ldots,z_{m})+g_{1}(x,z_{m})u
\end{align*}

\subsection{Feedback Linearization}
Feedback linearization is an approach based on a change of variables, transforming the nonlinear system into a linear one (seen from the controller perspective). In other words the nonlinearity gets ``hidden'' in a transformed input signal.

In order to apply this technique the system needs to be \textbf{differentially flat} with a \textbf{flat output} (see Section~\ref{diff_flatness}).
\newpar{}
To find the input transformation that linearizes a system of the form
\begin{align*}
    \dot{\mathbf{x}} & = f(\mathbf{x}) + g(\mathbf{x}) \mathbf{u} \\
    \mathbf{y}       & = h(\mathbf{x})
\end{align*}
the output $y$ has to be differentiated $\gamma$ times, where $\gamma$ (the relative degree) is the smallest number (if it exists) such that
\begin{equation*}
    L_g L_f^{\gamma-1} h(\mathbf{x}) \ne 0
\end{equation*}
with
\begin{align*}
    L_f h(\mathbf{x})     & := \frac{\partial h}{\partial \mathbf{x}}f(\mathbf{x})                                           \\
    L_g h(\mathbf{x})     & := \frac{\partial h}{\partial \mathbf{x}}g(\mathbf{x})                                           \\
    L_f^2 h(\mathbf{x})   & := L_f(L_f h(\mathbf{x})) = \frac{\partial L_f h(\mathbf{x})}{\partial \mathbf{x}}f(\mathbf{x})  \\
    L_g L_f h(\mathbf{x}) & := L_g (L_f h(\mathbf{x})) = \frac{\partial L_f h(\mathbf{x})}{\partial \mathbf{x}}g(\mathbf{x})
\end{align*}
where $L_f h(\mathbf{x})$ and $L_g h(\mathbf{x})$ are called the \textit{Lie derivatives} of $h(\mathbf{x})$ in direction $f$ or $g$ respectively.
\newpar{}
The system then can be transformed into a (virtually) linear system
\begin{equation*}
    \frac{d^\gamma \mathbf{y}}{dt^\gamma} = \mathbf{v}
\end{equation*}
by choosing a physical input
\begin{equation*}
    \mathbf{u} = \frac{1}{L_g L_f^{\gamma-1} h(\mathbf{x})}(-L_f^\gamma h(\mathbf{x}) + \mathbf{v})
\end{equation*}
A (linear, ``virtual'') realization of this system is given by
\begin{align*}
    \dot{\mathbf{x}} & = \begin{bmatrix}
                             0      & 1      & 0      & \cdots & 0      \\
                             0      & 0      & 1      & \cdots & 0      \\
                             \vdots & \vdots & \vdots & \ddots & \vdots \\
                             0      & 0      & 0      & \cdots & 1      \\
                             0      & 0      & 0      & \cdots & 0
                         \end{bmatrix}
    \mathbf{x} +
    \begin{bmatrix}
        0      \\
        0      \\
        \vdots \\
        0      \\
        1
    \end{bmatrix}
    \mathbf{v}                                                      \\
    y                & = \begin{bmatrix}
                             1 & 0 & \cdots & 0
                         \end{bmatrix}
    \mathbf{x}
\end{align*}

\newpar{}
Explicit examples for $\gamma = 1$ %(then $L_f h(x)=h(x)$)
\begin{align*}
    \dot{\mathbf{y}\mathbf{}} & = L_f h(\mathbf{x}) + L_g h(\mathbf{x}) \mathbf{u}             \\
    \dot{\mathbf{y}}          & = \mathbf{v}                                                   \\
    \mathbf{u}                & = \frac{1}{L_g h(\mathbf{x})}(-L_f h(\mathbf{x}) + \mathbf{v})
\end{align*}
and for $\gamma = 2$
\begin{align*}
    \ddot{\mathbf{y}} & = L_f^2 h(\mathbf{x}) + L_g L_f h(\mathbf{x}) \mathbf{u}             \\
    \ddot{\mathbf{y}} & = \mathbf{v}                                                         \\
    \mathbf{u}        & = \frac{1}{L_g L_f h(\mathbf{x})}(-L_f^2 h(\mathbf{x}) + \mathbf{v})
\end{align*}

\newpar{}
\ptitle{Remarks:}
\begin{itemize}
    \item Only works for \textbf{controllable} systems
    \item The actuator basically cancels out the behavior of the original system to replace it with the designed linear one.
    \item This has the disadvantage that potential good characteristics of the nonlinear system (like damping) get actively canceled out.
    \item One can imagine the FB linearization as controlling a virtual linear system with control input $v$ but under the hood applying a cleverly chosen physical control input $u$.
    \item Feedback linearization provides an exact linear model of a nonlinear system. Not like the Jacobian-Linearization which linearizes the system around an equilibrium point.
\end{itemize}

\begin{examplesection}[Pendulum]
    In the case of the nonlinear pendulum with a torque input $u$ and an output $y=\theta$
    \begin{align*}
        \dot{\mathbf{x}}_1 & = \mathbf{x}_2                                      \\
        \dot{\mathbf{x}}_2 & = -a \sin(\mathbf{x}_1)-c \mathbf{x}_2 + \mathbf{u} \\
        \mathbf{y}         & = \mathbf{x}_1
    \end{align*}
    The Lie derivatives are
    \begin{align*}
        L_f h(\mathbf{x}) & = \begin{bmatrix}
                                  1 & 0
                              \end{bmatrix}
        \begin{bmatrix}
            \mathbf{x}_2 \\
            -a \sin(\mathbf{x}_1) -c\mathbf{x}_2
        \end{bmatrix} = \mathbf{x}_2
        \\
        L_g h(\mathbf{x}) & = \begin{bmatrix}
                                  1 & 0
                              \end{bmatrix}
        \begin{bmatrix}
            0 \\
            1
        \end{bmatrix} = 0
    \end{align*}
    Since $L_g h(\mathbf{x}) = 0$ we need to differentiate again
    \begin{align*}
        L_f^2 h(\mathbf{x})   & = \begin{bmatrix}
                                      0 & 1
                                  \end{bmatrix}
        \begin{bmatrix}
            \mathbf{x}_2 \\
            -a \sin(\mathbf{x}_1) -c\mathbf{x}_2
        \end{bmatrix} = -a \sin(\mathbf{x}_1) -c \mathbf{x}_2
        \\
        L_g L_f h(\mathbf{x}) & = \begin{bmatrix}
                                      0 & 1
                                  \end{bmatrix}
        \begin{bmatrix}
            0 \\
            1
        \end{bmatrix} = 1
    \end{align*}
    This results in
    \begin{equation*}
        \mathbf{u} = \frac{1}{L_g L_f h(\mathbf{x})}(-L_f^2 h(\mathbf{x}) + \mathbf{v}) = a \sin(\mathbf{x}_1) + c \mathbf{x}_2 + \mathbf{v}
    \end{equation*}
    and the linear system
    \begin{align*}
        \dot{\mathbf{x}}_1 & = \mathbf{x}_2 \\
        \dot{\mathbf{x}}_2 & = \mathbf{v}   \\
        \mathbf{y}         & = \mathbf{x}_1
    \end{align*}
    with
    \begin{equation*}
        \mathbf{v} = -a \sin(\mathbf{x}_1)-c \mathbf{x}_2 + \mathbf{u}
    \end{equation*}
\end{examplesection}

\subsubsection{Differental Flatness}\label{diff_flatness}
A dynamic system
\begin{gather*}
    \dot{\mathbf{x}} = f(\mathbf{x},\mathbf{u}) \\
    \mathbf{y} = h(\mathbf{x},\mathbf{u})
\end{gather*}
is differentially flat, with flat output $\mathbf{y}$, if one can compute the state and input trajectories as a function (map $\Xi$) of the flat outputs and a finite number of derivatives.
\begin{equation*}
    (\mathbf{x},\mathbf{u}) = \Xi (\mathbf{y},\dot{\mathbf{y}}, \ldots, \mathbf{y}^{(m)})
\end{equation*}

\begin{examplesection}[Pendulum]
    The nonlinear pendulum with a torque input $\mathbf{u}$ and an output $\mathbf{y}=\theta$
    \begin{align*}
        \dot{\mathbf{x}}_1 & = \mathbf{x}_2                                      \\
        \dot{\mathbf{x}}_2 & = -a \sin(\mathbf{x}_1)-c \mathbf{x}_2 + \mathbf{u} \\
        \mathbf{y}         & = \mathbf{x}_1
    \end{align*}
    Is differentially flat with flat output $y$. As per definition $x$ and $u$ can be reconstructed from $y$, $\dot{y}$ and $\ddot{y}$.
    \begin{align*}
        \mathbf{x}_1 & = \mathbf{y}                                                  \\
        \mathbf{x}_2 & = \dot{\mathbf{y}}                                            \\
        \mathbf{u}   & = \ddot{\mathbf{y}} + c \dot{\mathbf{y}} + a \sin(\mathbf{y})
    \end{align*}
\end{examplesection}

\paragraph{Differental flat systems}
\begin{center}
    \includegraphics[width=\linewidth]{nonlinear_systems_diff_flat_1.png}
    \includegraphics[width=\linewidth]{nonlinear_systems_diff_flat_2.png}
\end{center}

\subsubsection{Feedback control of differentially-flat systems}
The geometric property of differential flatness allows to compute the input control signal and the internal state of a system given a desired, sufficient differentiable output trajectory. A problem arises if the actual initial state does not match the computed initial state. This deviation can be controlled by introducing a feedback loop into the virtual signal $\mathbf{v}$ depending on the desired output $\mathbf{y}_d$
\begin{equation*}
    \mathbf{v} = \mathbf{y}_d^{(\gamma)} + K \begin{bmatrix}
        \mathbf{y}_d - \mathbf{y}             \\
        \dot{\mathbf{y}}_d - \dot{\mathbf{y}} \\
        \vdots                                \\
        \mathbf{y}_d^{(\gamma-1)} - \mathbf{y}^{(\gamma-1)}
    \end{bmatrix}
\end{equation*}
or the desired internal state $\mathbf{x}_d$
\begin{equation*}
    \mathbf{v} = \mathbf{y}_d^{(\gamma)} + K \begin{bmatrix}
        \mathbf{x}_d - \mathbf{x}             \\
        \dot{\mathbf{x}}_d - \dot{\mathbf{x}} \\
        \vdots                                \\
        \mathbf{x}_d^{(\gamma-1)} - \mathbf{x}^{(\gamma-1)}
    \end{bmatrix}
\end{equation*}

\newpar{}
\ptitle{Remarks:}
\begin{itemize}
    \item Due to the coordinate transformation it becomes hard to check the control input e.g.\ for saturation bounds.
    \item The feedback is non-proper, i.e., it contains a number of differentiators that is equal to the relative degree
    \item The closed-loop dynamics are (internally) stable iff the zero dynamics are stable, i.e., if the system is minimum phase.
\end{itemize}

\subsubsection{Zero dynamics}
% By only looking at the input-output relationship $\mathbf{y}^{(\gamma)}=v$, one ignores the dynamics on a manifold of dimensions $n-\gamma$.
\ptitle{Checking for Asymptotic Minimum Phase}

If it is possible to find an input $\mathbf{u}_0(\mathbf{x})$ that satisfies
\noindent\begin{equation*}
    \mathbf{y}=\dot{\mathbf{y}}=\cdots=\mathbf{y}^{(\gamma)}=0
\end{equation*}
the \textbf{zero dynamics} (if they exist) are given by
\begin{equation*}
    \dot{\mathbf{x}} = f(\mathbf{x}) + g(\mathbf{x})\mathbf{u}_0(\mathbf{x})
\end{equation*}

Given an equilibrium point $f(\mathbf{x}_0)=0$ with zero output $h(\mathbf{x}_0)=0$, if the zero dynamics for the equilibrium point $\mathbf{x}_0$, i.e.\
\begin{equation*}
    \dot{\mathbf{x}} = f(\mathbf{x}_0) + g(\mathbf{x}_0)\mathbf{u}_0(\mathbf{x}_0)
\end{equation*}
are \textbf{asymptotically} (exponentially) \textbf{stable}, the system is said to be \textbf{asymptotically} (exponentially) \textbf{minimum-phase}.

% \newpar{}
% It is possible to find a $\mathbf{u}_0(x)$ such that $\mathbf{y}=\dot{\mathbf{y}}=\ddot{\mathbf{y}}=\cdots=\mathbf{y}^{(\gamma)}=0$, and still have non-trivial dynamics in the state space
% \begin{equation*}
%     \dot{\mathbf{x}} = f(\mathbf{x}) + g(\mathbf{x})\mathbf{u}_0(\mathbf{x})
% \end{equation*}
% This is called the \textbf{zero dynamics} of the system.

% In other words, there can be a control input that only excites the internal behavior of the system but does not affect the output (system is unobservable).
% \newpar{}
% Assume now that $f(x_0) = 0$, and $h(x_0) = 0$, i.e., that $x_0$ is an equilibrium point, with zero output. Then, the system is said to be asymptotically (exponentially) minimum-phase at $x_0$ if $x_0$ is an asymptotically (exponentially) stable equilibrium point for the zero dynamics.
\newpar{}
\ptitle{Breaking Condition}

If the system is not minimum-phase, the feedback linearization approach does not ensure internal stability of the closed-loop system, i.e., there are ``unobservable modes'' that are unstable.