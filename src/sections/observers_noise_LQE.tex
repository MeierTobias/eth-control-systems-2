\section{Observers}
\subsection{Luenberger Observer}
In case we desire full-state feedback but there are no sensors available to measure each state, we could try to simulate the system (with it's states).
\subsubsection{State Estimation Without Observer}
\begin{itemize}
    \item we choose $\hat{x_0}=0$
    \item the control input $u$ is computed from the simulated state
    \item both the simulated model and the physical plant receive the same control input
\end{itemize}
\begin{center}
    \includegraphics[width=0.8\linewidth]{images/state_feedback.png}\\
\end{center}
\ptitle{Estimation Error Dynamics}

\begin{itemize}
    \item the estimation error $\eta:=X-\hat{X}$ shares the dynamics of the OL system $\dot{\eta}=A\eta$!
    \item this can lead to undesirable estimation error dynamics (slow convergence, oscillations, divergence in case of unstable OL system)
    \item control basically disapears for the estimation error as we try to control the plant
\end{itemize}

\subsubsection{The Luenberger Observer}
We don't have to fully rely on our state estimation but can instead, use the available sensory information to improve it.
\begin{itemize}
    \item the signal $y-\hat{y}=C(x-\hat{x})$ is called \textbf{innovation} and is the input to the Luenberger \textbf{observer gain} $L$
    \item the Luenberger observer corrects the estimated state by a linear feedback on the innovation
    \item in other words we design a controller to get a good estimate of the physical plant's state
\end{itemize}
\begin{center}
    \includegraphics[width=0.8\linewidth]{images/Luenberger.png}
\end{center}
\ptitle{Estimation Error Dynamics}

The states evolve as follows:
\begin{align*}
    x^+       & =Ax+Bu                     \\
    \hat{x}^+ & =A\hat{x}+Bu+LC(x-\hat{x})
\end{align*}
Hence,
\begin{equation*}
    \eta^+=x^+-\hat{x}^+=A(x-\hat{x})-LC(x-\hat{x})=(A-LC)\eta
\end{equation*}

\subsubsection{Observer Pole Placement}
For state feedback we obtained the CL Eigenvalues $A-BK$. For the Luenberger observer we can state the \textbf{dual} problem, namely placing the poles of
\begin{equation*}
    A-LC
\end{equation*}
respectively
\begin{equation*}
    A^T-C^T L^T\text{ (same Eigenvalues)}
\end{equation*}
using the methods learned for state feedback.

\ptitle{Ackermann Observer Design}

The \textbf{Observability Matrix}
\begin{equation*}
    \mathcal{O}:=\begin{bmatrix}C\\CA\\\vdots\\CA^{n-1}\end{bmatrix}
\end{equation*}
must be invertible which is the case for observable SISO LTI systems.\\
Then, similarly to state feedback we get
\begin{align*}
    L                        & =\varphi_{\mathrm{cl}}(A)\mathcal{O}^{-1}\begin{bmatrix}0,&\ldots,&0,&1\end{bmatrix}^T \\
    \varphi_{\mathrm{cl}}(s) & =s^n+\alpha_{n-1}s^{n-1}+\ldots+\alpha_0=(s-\lambda_1)\ldots(s-\lambda_n)              \\
    \varphi_{\mathrm{cl}}(A) & =A^n+\alpha_{n-1}A^{n-1}+\ldots+\alpha_0I
\end{align*}
Remark: $\alpha_0$ must be multiplied by the identity matrix and not just added to every single matrix element.

\ptitle{Observer Pole Placement for Unobservable Systems}

Assumptions:
\begin{itemize}
    \item system is not observable (so at least one $c_j=0$)
    \item system is diagonalizable and given in modal coordinates
\end{itemize}
\begin{align*}
    \eta_1^+ & =\quad\lambda_1\eta_1-I_1\sum_{j=1}^n\left(\tilde{c}_j\eta_j\right) \\
    \vdots                                                                         \\
    \eta_n^+ & =\quad\lambda_n\eta_n-I_n\sum_{j=1}^n\left(\tilde{c}_j\eta_j\right)
\end{align*}
Then, if for example $\tilde{c_n}=0$,
\begin{itemize}
    \item $\eta_n^+$ cannot affect any of the other $\eta_j^+$
    \item $\lambda_n$ will remain a pole of the estimation error dynamics for any choice of $L$
\end{itemize}
Conclusions:
\begin{itemize}
    \item unobservable poles cannot be moved (cannot assign these poles)
    \item \textbf{observability} is a \textbf{necessary and sufficient} condition for arbitrary pole placement
    \item \textbf{detectability} is \textbf{necessary} for stable observer dynamics (as we need to observe the unstable poles)
\end{itemize}

\ptitle{Noise Sensitivity}

\begin{itemize}
    \item in the case of state feedback control, we could not choose arbitrarily large values for our control matrix $K$
    \item similarly, very large values for $L$ make our measurements more \textbf{sensitive to noise}
    \item hence, we need to find a trade-off between estimation dynamics and robustness to noise
\end{itemize}


\subsection{Noise Models}
We model noise as a stochastic process with a \textbf{noise signal}
\begin{equation*}
    w:t\mapsto w(t)\in\mathbb{R}^n
\end{equation*}where each $w(t)$ is the realization of a random variable.

\subsubsection{White Noise}
``Perfect'' but unphysical (values change instantaneously) noise can be modeled as follows:
\begin{enumerate}
    \item $\mathbb{E}[w(t)]=0$: the signal has zero mean.
    \item $\mathbb{E}[w(t){w(t)}^T]=W$: the signal value at each time instance has covariance $W$, for some positive definite matrix $W$.
    \item $\mathbb{E}[w(t){w(\tau)}^T]=0$: the signal values at two different times are not correlated. In fact, we will assume that signal values at two different times are \textbf{independent}.
\end{enumerate}
If such a signal additionally is Gaussian-distributed it is called ``zero mean Gaussian white noise``.

\subsubsection{Colored Noise}
To simulate physical noise we let a white noise input $w$ propagate through a LTI system model (filter) and use the system's output as noise signal:
\begin{align*}
    \dot{x} & =Ax+Bw \\
    y       & = Cx
\end{align*}
The LTI system usually acts as low-pass filter in this case.


\subsection{Linear Quadratic Estimation (LQE) Kalman Filter}
Note: this method can be applied only to \textbf{LTI systems}.\\
Noise affects our state estimation adversely. The LQE aims at an optimal trade-off between
\begin{itemize}
    \item trusting the sensory information and hence, having higher observer gains in $L$ (increases noise-sensitivity, left image)
    \item trusting the state-space model and hence, having lower observer gains in $L$ (decreases noise-sensitivity, right image)
\end{itemize}
\begin{center}
    \includegraphics[width=0.8\linewidth]{images/trade_off_noise.png}
\end{center}


\subsubsection{Optimal LQE Design}
For the LQE problem, we get the following LTI Model
\begin{align*}
    \dot{x}(t) & = Ax(t)+Bu(t)+w(t) \\
    y(t)       & = Cx(t)+n(t)
\end{align*}
with the Gaussian white noise signals
\begin{itemize}
    \item $w(t)$: process noise
    \item $n(t)$: sensor noise
\end{itemize}
We model the errors with the covariance matrices
\begin{align*}
    Q & =\mathbb{E}[w(t){w(t)}^T]                 & \text{ (process)} \\
    R & =\mathbb{E}[n(t){n(t)}^T], \forall t\geq0 & \text{ (sensor)}
\end{align*}
The (Luenberger) observer is given by
\begin{align*}
    \dot{\hat{x}}(t) & =(A-LC)\hat{x}(t)+Bu(t)+Ly(t) \\
    \hat{y}(t)       & =C\hat{x}(t)
\end{align*}

\ptitle{Minimization Problem}

The steady-state covariance of the state estimation error
\begin{equation*}
    \lim_{t\to+\infty}\mathbb{E}\left[(x(t)-\hat{x}(t)){(x(t)-\hat{x}(t))}^T\right]
\end{equation*}
is minimized by solving the Riccati equation
\begin{equation*}
    AY+YA^T-YC^T R^{-1}CY+Q=0
\end{equation*}
for the positive-definite matrix $Y$ and choosing the \textbf{optimal estimation gain} as
\begin{equation*}
    L=-YC^T R^{-1}
\end{equation*}

\ptitle{Remarks}

\begin{itemize}
    \item as expected from duality, $L$ is the transpose of $K$, obtained for the pair $(A^T, C^T)$, and for weight matrices $Q$ and $R$.
    \item in practice, we can measure the noise to get a first estimate of $Q$, $R$
    \item as a guideline, one should make the innovations as white as possible
    \item for large $Q$ w.r.t. $R$ we assume large process noise and hence, trust the sensors more than our model
    \item for large $R$ w.r.t. $Q$ we assume large sensor noise and hence, trust the model more than our sensors
\end{itemize}
