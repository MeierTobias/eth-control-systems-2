\section{MIMO Systems}

\subsection{State Space Representation}
\noindent\begin{align*}
    \underbrace{\dot{\mathbf{x}}}_{n\times 1} & = \underbrace{\mathbf{A}}_{n\times n}   \underbrace{\mathbf{x}}_{n\times1}+\underbrace{\mathbf{B}}_{n\times m}   \underbrace{\mathbf{u}}_{m\times1} \\
    \underbrace{\mathbf{y}}_{\ell\times 1}    & = \underbrace{\mathbf{C}}_{\ell\times n}\underbrace{\mathbf{x}}_{n\times1}+\underbrace{\mathbf{D}}_{\ell\times m}\underbrace{\mathbf{u}}_{m\times1}
\end{align*}
with
\begin{itemize}
    \item $\mathbf{x}\in\mathbb{R}^n$, where $n$ is the order of the system.
    \item $\mathbf{u}\in\mathbb{R}^m$, where $m$ is the number of inputs.
    \item $\mathbf{y}\in\mathbb{R}^\ell$, where $\ell$ is the number of outputs.
\end{itemize}

\subsection{TF Matrix}

\ptitle{Continuous Time}

For an elementary input vector $\mathbf{u}(t)$ we get the steady state output vector
\begin{equation*}
    \mathbf{y}_{{\mathrm{ss}}}(t)=\mathbf{G}(s)\mathbf{u}(t)=
    \begin{bmatrix}G_{11}(s)    & \ldots & G_{1m}(s)     \\
               \vdots       & \ddots & \vdots        \\
               G_{\ell1}(s) & \ldots & G_{\ell m}(s)
    \end{bmatrix}
    \underbrace{
    \begin{bmatrix}u_{1}  \\
        \vdots \\
        u_{m}
    \end{bmatrix}e^{st}}_{\mathbf{u}(t)}
\end{equation*}
where $\mathbf{G}(s)\in\mathbb{\mathbb{C}}^{\ell\times m}$ is a complex-valued matrix for $s\in \mathbb{C}$. The transfer function is then given by
\begin{equation*}
    \mathbf{G}(s)=\mathbf{C}\cdot{(s\cdot\mathbf{I}-\mathbf{A})}^{-1}\cdot \mathbf{B}+\mathbf{D}
\end{equation*}

\ptitle{Discrete Time}

The same holds for the discrete time case where $s^{st}$ is replaced by $z^k$ and $s$ by $z$. For further details see~\ref{disc:tf}.

\newpar{}
\ptitle{Remarks}
\begin{itemize}
    \item Diagonal TF matrices represent \textbf{decoupled} systems
    \item non-diagonal entries describe the relation of a certain input and a certain output
\end{itemize}

\subsubsection{Interconnections}

To find the interconnection start at output $\mathbf{y}$ and proceed against signal flow towards the input $\mathbf{u}$

\newpar{}
\ptitle{Series Interconnection}
\newpar{}
\begin{center}
    \input{BSB/mimo_series.tex}
\end{center}

\begin{equation*}
    \mathbf{y}=\mathbf{G_2G_1u}
\end{equation*}

\newpar{}
\ptitle{feedback interconnection}
\newpar{}
\begin{center}
    \input{BSB/mimo_feedback.tex}
\end{center}

\begin{equation*}
    \mathbf{y}={(\mathbf{I}+\mathbf{G_1G_2})}^{-1}\mathbf{G_1u}
\end{equation*}


\subsection{Poles}

\begin{itemize}
    \item In MIMO systems the poles are the eigenvalues of $\mathbf{A}$.
    \item The \textbf{minors} are all single entries of the $\mathbf{G}(s)$ matrix as well as all possible square matrices (of all sizes!) in $\mathbf{G}(s)$. % TODO: what does that mean?
    \item The \textbf{characteristic polynomial} $d(s)$ of a minimal realization of $\mathbf{G}(s)$ is the least common multiple (LCM) of the denominators of all possible minors $G_{ij}$.
    \item The \textbf{poles} of $\mathbf{G}(s)$ are the roots of the aforementioned LCM term.
\end{itemize}

\newpar{}
\ptitle{Stability}

Same condition as in SISO systems:
\begin{itemize}
    \item \textbf{Stable} if $\mathrm{Re}(p_i \le 0)$ and the algebraic multiplicity of poles with zero real part is equal to their geometric multiplicity.
    \item \textbf{Asymptotically stable}\ if $\mathrm{Re}(p_i<0)$
\end{itemize}


\subsection{Zeros}
\begin{itemize}
    \item One can find MIMO zeros either from $\mathbf{G}(s)$ (transmission zeros) or from state space representation (invariant zeros).
    \item For minimal realizations they are the same.
          % \item Similar to eigenvalues and their eigenvectors (as known from poles) we have zero frequencies and associated zero vectors.
\end{itemize}

\subsubsection{Transmission Zeros}

$z_0$ is a transmission zero if there exists a non-zero, rational function $\mathbf{u}_0(s)$ such that
\begin{equation*}
    \lim_{s\to z_0}\left[\mathbf{G}(s)\mathbf{u}_0(s)\right]e^{st}=0,\quad\forall t\geq0
\end{equation*}
which means that $\mathbf{\mathbf{G}}(s)$ \textbf{loses rank} for $s\to z_0$.

\ptitle{Remarks}

\begin{itemize}
    \item A MIMO transmission zero is a pair of frequency $z_0$ and direction $\mathbf{u}_0(z_0)$.
    \item It can happen that a zero of $\mathbf{G}$ is not visible in any of it's entries $G_{ij}(s)$.
    \item The direction of the zero decides whether a MIMO pole and zero at the same frequency \textbf{cancel} (i.e.\ there can be a pole and a zero at same frequency without cancellation!).
    \item A zero means not just one entry of $\mathbf{y}$ is zero but that given an input vector $\mathbf{u} \ne \mathbf{0}$, $\mathbf{y}$ becomes the zero vector.
\end{itemize}

\subsubsection{Invariant Zeros}

Invariant zeros are the values of $s$ for which the following matrix becomes singular and therefor the determinant of the matrix is zero:
\begin{equation*}
    \det \left(\begin{bmatrix}
            s\mathbf{I}-\mathbf{A} & -\mathbf{B} \\
            \mathbf{C}             & \mathbf{D}
        \end{bmatrix}\right) \overset{!}{=}0
\end{equation*}
The corresponding input vectors can then be determined by plugging the invariant zeros into the equation below:
\begin{equation*}
    \begin{bmatrix}
        s\mathbf{I}-\mathbf{A} & -\mathbf{B} \\
        \mathbf{C}             & \mathbf{D}
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{x}_i \\
        \mathbf{u}_i
    \end{bmatrix}=\mathbf{0}
\end{equation*}

\ptitle{Remarks}

\begin{itemize}
    \item An invariant zero $z_i$ is associated with a vector $\mathbf{u}_i$.
    \item Given zero initial condition and $\mathbf{u}(t)=\mathbf{u}_i e^{s_i t}$ (zero direction and zero frequency) we get
          \begin{equation*}
              \mathbf{y}(t)=-\mathbf{C}e^{\mathbf{A}t}\mathbf{x_i}
          \end{equation*} which is independent of the input and becomes $0$ for a corresponding non-zero initial condition.
    \item For non-minimal realizations invariant zeros can give additional zeros (correspond to uncontrollable/unobservable modes).
\end{itemize}


\subsection{Realizations of MIMO Systems}
\subsubsection{Naive Realization}
Compute realization of each component of $\mathbf{G}(s)$ and assemble them to a new state space model.
\begin{align*}
    \mathbf{A} & =\begin{bmatrix}
                      \mathbf{A}_{11} &                 &        &                 \\
                                      & \mathbf{A}_{12} &        &                 \\
                                      &                 & \ddots &                 \\
                                      &                 &        & \mathbf{A}_{lm} \\
                  \end{bmatrix},
    \quad \mathbf{B}  =\begin{bmatrix}
                           \mathbf{b}_{11} &                 &                 \\
                                           & \mathbf{b}_{12} &                 \\
                                           &                 & \ddots          \\
                           \mathbf{b}_{21} &                 &                 \\
                                           & \ddots          &                 \\
                                           &                 & \mathbf{b}_{lm} \\
                       \end{bmatrix}                                                                    \\
    \mathbf{C} & =\begin{bmatrix}
                       & \mathbf{c}_{11} & \mathbf{c}_{12} & \dots &                 &       &        &                 &       &                 \\
                       &                 &                 &       & \mathbf{c}_{21} & \dots &        &                 &       &                 \\
                       &                 &                 &       &                 &       & \ddots &                 &       &                 \\
                       &                 &                 &       &                 &       &        & \mathbf{c}_{l1} & \dots & \mathbf{c}_{lm} \\
                  \end{bmatrix} \\
    \mathbf{D} & = \begin{bmatrix}
                       \mathbf{d}_{11} & \dots  & \mathbf{d}_{1m} \\
                       \vdots          & \ddots & \vdots          \\
                       \mathbf{d}_{l1} & \dots  & \mathbf{d}_{lm} \\
                   \end{bmatrix}
\end{align*}

\ptitle{Problems}

\begin{itemize}
    \item non-minimal
    \item redundant poles (sum of entrie's poles)
\end{itemize}

\subsubsection{Gilbert's Realization}

Given
\begin{equation*}
    \mathbf{G}(s)=\frac{\mathbf{H}(s)}{d(s)}+\mathbf{D}
\end{equation*}
where
\begin{itemize}
    \item $d(s)$ is the least common denominator of all entries in $\mathbf{G}(s)$
    \item $\mathbf{D}=\lim_{s\to\infty}\mathbf{G}(s)$ is the feed-through term.
\end{itemize}

\newpar{}
Then, if $d(s)$ has no repeated roots, one can use \textbf{Gilbert's method}:

\newpar{}
\begin{enumerate}
    \item Write a (matrix) partial fraction expansion of $\frac{\mathbf{H}(s)}{d(s)}$
          \begin{equation*}
              \mathbf{G}(s)=\frac{\mathbf{R_1}}{s-p_1}+\frac{\mathbf{R_2}}{s-p_2}+\ldots+\frac{\mathbf{R_{n_d}}}{s-p_{n_d}}+\mathbf{D}
          \end{equation*} with the residues
          \begin{equation*}
              \mathbf{R_i}=\lim_{s\to p_i}(s-p_i)\mathbf{G}(s)
          \end{equation*}
          \begin{itemize}
              \item The ranks $r_i$ of $\mathbf{R_i}$ indicate the number of poles at location $p_i$ that are needed for the realization.
              \item The order of the resulting state space model will be $n=\sum_{i=1}^{n_d}r_i\geq n_d$
              \item Ensure that $d(s)$ has no repeated roots (otherwise one has to use the generalized Gilbert's method).
              \item Check $n\le n_d$ after calculating $r_i$.
          \end{itemize}
    \item Write $\overbrace{\mathbf{R_i}}^{l\times m}=\mathbf{\overbrace{\mathbf{C}_i}^{l\times r_i}\overbrace{ \mathbf{B}_i}^{r_i \times m}}$ for some $\mathbf{B_i}$, $\mathbf{C_i}$ so that
          \begin{itemize}
              \item $\mathbf{B_i}$ has $m$ (\# inputs) columns
              \item $\mathbf{C_i}$ has $l$ (\# outputs) rows
              \item $\mathbf{B_i}$ and $\mathbf{C_i}$ have $r_i$ independent rows/columns
          \end{itemize}
    \item Assemble the state space model as
          \begin{gather*}
              \mathbf{A}  =\begin{bmatrix}
                  p_1 \mathbf{I}_{r_1\times r_1} &                                &        &                                            \\
                                                 & p_2 \mathbf{I}_{r_2\times r_2} &        &                                            \\
                                                 &                                & \ddots &                                            \\
                                                 &                                &        & p_{n_d} \mathbf{I}_{r_{n_d}\times r_{n_d}} \\
              \end{bmatrix} \\
              \mathbf{B}  =\begin{bmatrix}
                  \mathbf{B}_1     \\
                  \mathbf{B}_2     \\
                  \vdots           \\
                  \mathbf{B}_{n_d} \\
              \end{bmatrix}, \quad
              \mathbf{C}  =\begin{bmatrix}
                  \mathbf{C}_1 & \mathbf{C}_2 & \dots & \mathbf{C}_{n_d} \\
              \end{bmatrix}, \quad
              \mathbf{D} = \mathbf{D}
          \end{gather*}
\end{enumerate}

\ptitle{Remarks}

\begin{itemize}
    \item Figures out the minimum number of ``copies'' of each pole that we need to construct a realization of a MIMO transfer function.
\end{itemize}

% TODO: Add an example?
% \begin{examplesection}[Example of Gilbert's Realization]
%     Given the TF
%     \begin{equation*}
%         \mathbf{G}(s) = \begin{bmatrix}
%             1 & \frac{1}{s+1} \\
%             0 & 1
%         \end{bmatrix}
%     \end{equation*}
%     The LCM denominator $d(s)$ is
%     \begin{equation*}
%         d(s) = s+1
%     \end{equation*}
%     and the feed-through term is
%     \begin{equation*}
%         \mathbf{D} = \mathbf{I}
%     \end{equation*}
%     
% \end{examplesection}

\subsection{Signal Amplification}

\subsubsection{Norms}

\ptitle{Properties}
\begin{align*}
     & \left\| a\mathbf{x}\right\|  =\left|a\right|\left\|\mathbf{x}\right\|,\quad\forall a\in\mathbb{R},\mathbf{x}\in V                 & \text{(homogeneity)}         \\
     & \left\|\mathbf{x}+\mathbf{y}\right\|                         \leq\|\mathbf{x}\|+\|\mathbf{y}\|                                    & \text{(triangle inequality)} \\
     & \left\|\mathbf{x}\right\|                >0 \text{ for } \mathbf{x}\neq0, \left\|\mathbf{x}\right\|=0\leftrightarrow \mathbf{x}=0 & \text{(positivity)}
\end{align*}

\ptitle{Example Norms}
\begin{itemize}
    \item Euclidean norm: $\left\|\mathbf{x}\right\|=\sqrt{\mathbf{x}^{\mathsf{H}}\mathbf{x}}$
    \item For Hermitian, pos.\ definite matrices: $\left\|\mathbf{x}\right\|=\sqrt{\mathbf{x}^{\mathsf{H}} Qx}$
    \item p-norm: $\|\mathbf{x}\|_p{=\left(\sum_{i=1}^n x_i^p\right)}^{1/p}$ with the important cases
          \begin{align*}
               & \|\mathbf{x}\|_1=\sum_1^n\left|x_i\right|,               \\
               & \|\mathbf{x}\|_2=\sqrt{\sum_{i=1}^n {x_i}^2}             \\
               & \left\|\mathbf{x}\right\|_\infty=\max_i\left|x_i\right|.
          \end{align*}
\end{itemize}

\subsubsection{Matrix Norms}
A $m\times n$ complex matrix can be seen as an operator between the vector spaces $\mathbb{C}^n$ and $\mathbb{C}^m$ i.e.
\begin{equation*}
    \mathbf{A}^{m\times n}:\mathbb{C}^n\to\mathbb{C}^m,\mathbf{x}\mapsto \mathbf{A}x
\end{equation*}
If we then provide the vector spaces with a norm, a \textbf{matrix norm is induced} by the norms of the vector spaces it operates on.

\begin{equation*}
    \|\mathbf{A}\|_p:=\sup_{\mathbf{x}\neq0}\frac{\|\mathbf{Ax}\|_p}{\|\mathbf{x}\|_p}=\max_{\|\mathbf{x}\|_p=1}\|\mathbf{Ax}\|_p
\end{equation*}
which means that the induced p-norm of $\mathbf{A}$ measures how much multiplication by $\mathbf{A}$ amplifies the p-norm of a vector. In other words, $\|\mathbf{A}\|_p$ is the \textbf{gain} of the operator $\mathbf{A}$.

\newpar{}
\ptitle{Properties of Induced Norms}

As for vectors, homogeneity, triangle inequality and positivity hold for matrix norms too. Additionally we have:
\begin{equation*}
    \left\|\mathbf{Ax}\right\|_p\leq\left\|a\right\|_p\left\|\mathbf{x}\right\|_p
\end{equation*}
and the submultiplicative property:
\begin{align*}
    \|\mathbf{AB}\|_p                                     & \leq\|\mathbf{A}\|_p\|\mathbf{B}\|_p                                                      \\
    \|\mathbf{AB} \mathbf{x}\|_p                          & \leq\|\mathbf{A}\|_p\|\mathbf{Bx}\|_p\leq\|\mathbf{A}\|_p\|\mathbf{B}\|_p\|\mathbf{x}\|_p \\
    \frac{\|\mathbf{AB} \mathbf{x}\|_p}{\|\mathbf{x}\|_p} & \leq\|\mathbf{A}\|_p\|\mathbf{B}\|_p
\end{align*}


\paragraph{Specific Induced Norms}

For the $p = 1$ norm we get
\begin{equation*}
    \|\mathbf{A}\|_1=\max_j\sum_{i=1}^m|a_{ij}|
\end{equation*}

For the $p = \infty$ norm we get
\begin{equation*}
    \|\mathbf{A}\|_\infty=\max_i\sum_{j=1}^n|a_{ij}|
\end{equation*}

\ptitle{Frobenius Norm}

\begin{equation*}
    \|\mathbf{A}\|_F:={\left(\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2\right)}^{1/2}=\text{Trace}{(\mathbf{A}^{\mathsf{H}}\mathbf{A})}^{1/2}
\end{equation*}

\begin{itemize}
    \item non-induced
    \item still has submultiplicative property
\end{itemize}
